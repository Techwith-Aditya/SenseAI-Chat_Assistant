API Key: "Your_API_Key"
______________________________________________________________________________

Your Code editor should contain these files in same folder:
requirements.txt (openai)
llama.py (has the code)
______________________________________________________________________________

Environment Setup:
python -m venv venv (Creating the Environment)
venv\Scripts\activate (Activating the Environment)
pip install -r requirements.txt (Install the Dependencies)

then Run the llama.py
______________________________________________________________________________


Code:
(llama.py)
from openai import OpenAI

client = OpenAI(
    base_url="https://integrate.api.nvidia.com/v1",
    api_key="Your_API_Key"
)

while True:
    user_input = input("Enter your question (or type 'exit' to quit): ")

    if user_input.lower() == "exit":
        print("Goodbye!")
        break

    # Request completion from LLaMA model
    completion = client.chat.completions.create(
        model="meta/llama-3.1-8b-instruct",
        messages=[{"role": "user", "content": user_input}],
        temperature=0.2,
        top_p=0.7,
        max_tokens=1024,
        stream=True
    )

    # Stream and print the response
    print("AI's response:")
    for chunk in completion:
        if chunk.choices[0].delta.content is not None:
            print(chunk.choices[0].delta.content, end="")
    print("\n")

    for chunk in completion:
        if chunk.choices[0].delta.content is not None:
            print(chunk.choices[0].delta.content, end="")
    print("\n")  # Add a newline for better readability after each response


